## 前置知识

### 什么是Agent

Agent = 循环+思考+执行

能够经过思考后决策，做工具栈的调用，该过程不可通过统计学获得规律（机械决策和智能决策的区别）

一个Agent是一个IPO模块，内部当然有可能是通过workflow实现的，这不影响这个IPO模块是个Agent

### 什么是RAG

RAG（检索增强生成）是一种将**信息检索**和**大语言模型生成**相结合的技术框架。它的核心思想是，在让大模型回答问题之前，先从一个外部知识库（如您的文档、数据库）中查找相关信息，然后将这些信息作为上下文提供给模型，最终生成一个**更准确、更可靠**的答案。

####  RAG的工作原理：分步详解

RAG的工作流程可以清晰地划分为**索引**和**查询**两大阶段。

##### ​**阶段一：索引 - 构建知识库**​

这个阶段是为您的外部知识（如公司文档、产品手册、法规条文）建立索引，以便快速检索，通常是一次性完成的。

1. ​**文档分块**​：首先将长篇文档分割成更小的、语义完整的文本块（例如，按段落或固定字数）。这是因为大模型有输入长度限制，且更小的块有助于提高检索精度。
    
2. ​**向量化**​：使用一个**嵌入模型**将这些文本块转换为数学意义上的向量（一组数字）。这个向量可以理解为文本在高维空间中的“坐标”，语义相近的文本，其向量在空间中的距离也更近。
    
3. ​**存储**​：将这些向量及其对应的原始文本存储到专门的**向量数据库**​（如Chroma, FAISS, Milvus）中。
    

##### ​**阶段二：查询 - 回答问题**​

当用户提出一个问题时，以下流程被触发：

1. ​**查询向量化**​：将用户的问题通过同样的嵌入模型转换为一个查询向量。
    
2. ​**检索**​：向量数据库负责在大量的向量中，快速找出与查询向量最相似的几个文本块（通常使用余弦相似度等算法）。
    
3. ​**增强与生成**​：将检索到的最相关的文本块作为附加的上下文信息，与用户的原始问题一起组合成一个详细的提示，然后发送给大语言模型（如GPT-4）。模型基于这个“被增强”的提示生成最终答案。
    

####  为什么需要RAG？它解决了三大核心难题

1. ​**化解“幻觉”，提升准确性**​：大模型有时会基于其训练数据“编造”出看似合理但事实错误的答案，这种现象被称为“幻觉”。RAG通过提供来自可信知识源的具体事实依据，让模型“有据可依”，显著降低胡说八道的概率。
    
2. ​**知识实时更新，打破模型记忆壁垒**​：大模型的知识局限于其训练数据截止的日期。对于最新的、非公开的或高度专业的信息，它无法知晓。而RAG可以直接从您随时更新的知识库中检索信息，让模型能够回答关于最新事件、公司内部政策或特定领域的问题。
    
3. ​**保障数据安全与来源可追溯**​：由于所有检索内容都来自您指定的、可控的知识库，敏感数据无需上传至第三方模型。同时，答案来源于哪些文档可以被追踪，增强了回答的可解释性和可信度。
    

#### ⚡️ RAG的演进：从朴素到模块化

根据复杂度和应用场景的不同，RAG系统可以分为几个层次：

| 范式           | 特点                             | 适用场景          |
| ------------ | ------------------------------ | ------------- |
| ​**朴素RAG**​  | 基础流程，简单直接，但检索精度和抗干扰能力较弱。       | 概念验证、简单问答     |
| ​**高级RAG**​  | 在检索前后进行优化，如查询重写、重排序等，显著提升效果。   | 大多数生产级应用      |
| ​**模块化RAG**​ | 像搭积木一样自由组合功能（如多路检索、智能代理），极度灵活。 | 复杂、高度定制化的企业系统 |

#### 🛠️ 典型应用场景

- ​**智能客服与问答系统**​：基于产品文档或知识库，提供精准的自动问答服务。
    
- ​**企业级知识助手**​：为员工快速查询内部规章制度、技术文档、历史项目信息。
    
- ​**内容创作与研究报告**​：快速整合多份报告、文章中的信息，辅助生成内容摘要或分析报告。
    
- ​**学术与法律研究**​：快速定位相关案例、法条或学术论文，提高研究效率。


### LangChain

### 业内常见的基于Go的Agent项目
| 项目名称                | 主要特点 / 技术定位                                                                     | 核心优势 / 背景                                                                                          | 开源方  |
| ------------------- | ------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- | ---- |
| ​**Eino**​          | 大模型应用开发框架，提供稳定的内核、灵活的扩展性和完善的工具生态。支持通过 ​**Chain（链）​**​ 和**Graph（图）​**​ 进行灵活编排。   | 字节跳动开源，背靠豆包、抖音等应用的丰富实践经验<br><br>。其 ​**Eino ADK (Agent Development Kit)​**​ 提供了预构建的智能体协作模式<br><br>。 | 字节跳动 |
| ​**tRPC-Agent-Go**​ | 偏向于**自主多Agent协作**的框架，同时提供工作流编排能力以兼容存量业务。集成了LLM、规划器、会话管理、知识库（RAG）等完整技术栈。         | 基于腾讯内部广泛使用的 tRPC 微服务框架，天然具备高性能和高可用性，与腾讯云生态结合紧密。                                                    | 腾讯   |
| ​**SwarmGo**​       | 轻量级、高度可控的库，专注于创建能够**相互交互和协调**的AI Agent网络。核心抽象是 ​**Agent**​ 和 ​**handoff**​（转交）。 | 设计注重轻量化和模块化，易于测试和控制，适合构建需要复杂交互的智能体系统<br><br>。                                                      |      |
### 业内常见Agent设计模式

构建AI智能体时，可以将软件工程中的经典设计模式（如责任链、工厂模式）与AI领域特有的架构模式（如ReAct、反思）相结合，以创建结构清晰、能力强健的系统。下表为您系统梳理了这些模式及其应用场景。

| 模式类别            | 设计模式          | 核心思想                                                               | 在智能体中的应用场景                                                                                                 |
| --------------- | ------------- | ------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------- |
| ​**经典软件设计模式**​  | ​**责任链模式**​   | 将多个处理对象串成链，请求沿链传递，直至被处理。                                           | 在Spring AI等框架的`BaseAgent`、`ReActAgent`等类中，定义了智能体的核心执行流程，其`run`方法中的步骤循环可被视为一种责任链，依次处理“思考-行动-观察”等环节。         |
|                 | ​**工厂模式**​    | 定义一个创建对象的接口，但由子类决定实例化哪个类。                                          | 用于根据配置或上下文动态创建不同类型的智能体（如`ReActAgent`, `ToolCallAgent`）或工具，提供统一的构建入口，提升灵活性和可维护性。                            |
|                 | ​**模板方法模式**​  | 在父类中定义算法骨架，子类在不改变结构的前提下重定义特定步骤。                                    | 在Spring AI的`BaseAgent`抽象基类中，`run()`方法定义了智能体的主循环模板，而具体的`step()`、`think()`、`act()`等方法则由子类实现，实现了通用逻辑和特定步骤的解耦。 |
| ​**AI智能体核心模式**​ | ​**ReAct模式**​ | ​**推理(Reason)​**与**行动(Act)​**循环，行动后产生**观察(Observation)​**，持续至问题解决。 | 处理需要多步骤推理和工具调用的复杂任务（如“查找当前法国人口并与德国比较”）。LLM在每一步生成思考轨迹和要执行的动作，是应用最广泛的智能体架构之一。                                |
|                 | ​**反思模式**​    | 智能体生成结果后，进行自我评估或交叉评估，根据反馈迭代优化输出。                                   | 适用于对输出质量要求高的场景，如代码生成、文书撰写。可通过**自我反思**、**交叉反思**​（由另一个模型评估）或**人类反思**实现。                                      |
|                 | ​**工具使用模式**​  | 智能体通过调用外部工具（搜索引擎、API、数据库）扩展能力，突破模型固有知识限制。                          | 获取实时信息（天气、新闻）、执行专业操作（计算、发送邮件）、或通过RAG从知识库获取精准信息。是智能体与现实世界交互的关键。                                             |
|                 | ​**规划模式**​    | 将复杂任务分解为一系列有序的子任务或步骤，然后按计划执行。                                      | 处理有清晰步骤的复杂任务（如旅行规划、项目开发）。​**LLM Compiler**是该模式的进阶，通过有向无环图实现子任务的并行执行，提升效率。                                  |
|                 | ​**多智能体协作**​  | 多个具备不同角色或专长的智能体通过通信、协作共同完成一项复杂任务。                                  | 解决单一智能体难以处理的复杂问题（如软件公司模拟ChatDev）。协作机制包括**分工协作**、**投票/辩论**达成共识、**层级管理**​（Orchestrator-Worker）等。             |

## 第一阶段：实现无历史智能对话

### 文件结构 
```
gin-ai-agent/
├── cmd/
│   └── server/
│       └── main.go          # 应用入口，依赖注入和路由初始化
├── internal/
│   ├── handler/
│   │   └── ai_handler.go    # HTTP 请求处理器
│   ├── service/
│   │   └── ai_service.go    # 业务逻辑层
│   ├── repository/
│   │   └── ai_repo.go       # 数据访问层
│   └── model/
│       ├── request.go       # 统一请求结构体
│       └── response.go      # 统一响应结构体
├── pkg/
│   └── config/
│       └── config.go        # 配置管理
├── go.mod
└── go.sum
```

### OpenAI规范

```python
from openai import OpenAI  
    client = OpenAI(api_key="YOUR_KEY", base_url="https://api.siliconflow.cn/v1")  

    response = client.chat.completions.create(  
        model="deepseek-ai/DeepSeek-V3",  
        messages=[  
            {"role": "system", "content": "You are a helpful assistant."},  
            {"role": "user", "content": "Write a haiku about recursion in programming."}  
        ],  
        temperature=0.7,  
        max_tokens=1024,
        stream=True
    )  
    # 逐步接收并处理响应
    for chunk in response:
        if not chunk.choices:
            continue
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
        if chunk.choices[0].delta.reasoning_content:
            print(chunk.choices[0].delta.reasoning_content, end="", flush=True)
```

**记得加上/chat/completion**